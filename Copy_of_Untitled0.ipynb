{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPAoBII9b8QzEW/k5rqzWKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/breakingcircuits1337/LLM1/blob/main/Copy_of_Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First cell - Installation and imports\n",
        "!pip install faiss-cpu\n",
        "!pip install pyyaml\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import faiss\n",
        "import logging\n",
        "import yaml\n",
        "from typing import List, Dict, Any, Optional, Tuple, Union\n",
        "from io import StringIO\n",
        "import time\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Enable mixed precision for better performance\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Second cell - Configuration\n",
        "# Reduced size configuration for Colab\n",
        "config_yaml = \"\"\"\n",
        "n_vocab: 50000\n",
        "n_ctx: 512      # Reduced context length\n",
        "n_embd: 256     # Reduced embedding dimension\n",
        "n_head: 8       # Reduced number of heads\n",
        "n_layer: 6      # Reduced number of layers\n",
        "learning_rate: 1e-4\n",
        "n_hash: 512     # Reduced hash size\n",
        "n_quant: 128    # Reduced quantization size\n",
        "num_results: 5\n",
        "dim: 256        # Matching embedding dimension\n",
        "\"\"\"\n",
        "\n",
        "config = yaml.safe_load(StringIO(config_yaml))\n",
        "\n",
        "# Third cell - Helper Functions\n",
        "def gelu(x):\n",
        "    \"\"\"Gaussian Error Linear Unit activation function\"\"\"\n",
        "    return 0.5 * x * (1 + tf.math.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * tf.math.pow(x, 3))))\n",
        "\n",
        "# Fourth cell - Model Components\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"Multi-head attention layer optimized for Colab\"\"\"\n",
        "    def __init__(self, n_embd: int, n_head: int):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_embd = n_embd\n",
        "        self.n_head = n_head\n",
        "        self.head_dim = n_embd // n_head\n",
        "\n",
        "        # Use smaller initialization scale for better numerical stability\n",
        "        initializer = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "\n",
        "        self.c_attn = tf.keras.layers.Dense(3 * n_embd, kernel_initializer=initializer)\n",
        "        self.c_proj = tf.keras.layers.Dense(n_embd, kernel_initializer=initializer)\n",
        "        self.attn_dropout = tf.keras.layers.Dropout(0.1)\n",
        "        self.resid_dropout = tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        x = tf.reshape(x, [batch_size, -1, self.n_head, self.head_dim])\n",
        "        return tf.transpose(x, [0, 2, 1, 3])\n",
        "\n",
        "    def merge_heads(self, x):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        x = tf.transpose(x, [0, 2, 1, 3])\n",
        "        return tf.reshape(x, [batch_size, -1, self.n_embd])\n",
        "\n",
        "    # The call function should be indented within the class definition\n",
        "    def call(self, x, mask=None, training=False):\n",
        "        q, k, v = tf.split(self.c_attn(x), 3, axis=-1)\n",
        "        q = self.split_heads(q)\n",
        "        k = self.split_heads(k)\n",
        "        v = self.split_heads(v)\n",
        "\n",
        "        # Scaled dot-product attention with memory-efficient implementation\n",
        "        scale = tf.math.sqrt(tf.cast(self.head_dim, tf.float32))\n",
        "\n",
        "        # Cast q and k to float32 before matrix multiplication\n",
        "        q = tf.cast(q, tf.float32)\n",
        "        k = tf.cast(k, tf.float32)\n",
        "\n",
        "        scores = tf.matmul(q, k, transpose_b=True) / scale\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores + (1.0 - tf.cast(mask, scores.dtype)) * -1e9\n",
        "\n",
        "        weights = tf.nn.softmax(scores, axis=-1)\n",
        "        weights = self.attn_dropout(weights, training=training)\n",
        "\n",
        "        a = tf.matmul(weights, v)\n",
        "        a = self.merge_heads(a)\n",
        "        a = self.c_proj(a)\n",
        "        a = self.resid_dropout(a, training=training)\n",
        "\n",
        "        return a\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Transformer block optimized for Colab\"\"\"\n",
        "    def __init__(self, n_embd: int, n_head: int):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.n_embd = n_embd\n",
        "        self.n_head = n_head\n",
        "\n",
        "        self.ln_1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = MultiHeadAttention(n_embd, n_head)\n",
        "        self.ln_2 = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(4 * n_embd, activation=gelu),\n",
        "            tf.keras.layers.Dropout(0.1),\n",
        "            tf.keras.layers.Dense(n_embd),\n",
        "            tf.keras.layers.Dropout(0.1)\n",
        "        ])\n",
        "\n",
        "    def call(self, x, mask=None, training=False):\n",
        "        a = self.attn(self.ln_1(x), mask=mask, training=training)\n",
        "        x = x + a\n",
        "        m = self.mlp(self.ln_2(x), training=training)\n",
        "        x = x + m\n",
        "        return x\n",
        "\n",
        "class FAISSRetriever:\n",
        "    \"\"\"Memory-efficient FAISS retriever\"\"\"\n",
        "    def __init__(self, knowledge_base: List[Dict[str, Any]], dim: int, num_results: int):\n",
        "        self.index = faiss.IndexFlatL2(dim)\n",
        "        self.knowledge_base = knowledge_base\n",
        "        self.num_results = min(num_results, len(knowledge_base))\n",
        "\n",
        "        vectors = [np.array(doc['vector'], dtype=np.float32).reshape(1, -1)\n",
        "                  for doc in knowledge_base]\n",
        "        self.index.add(np.concatenate(vectors, axis=0))\n",
        "\n",
        "    def retrieve(self, query_vector: tf.Tensor) -> tf.Tensor:\n",
        "        query_np = tf.cast(query_vector, tf.float32).numpy()\n",
        "        distances, indices = self.index.search(query_np, self.num_results)\n",
        "        retrieved_docs = [[self.knowledge_base[i]['text'] for i in batch]\n",
        "                         for batch in indices]\n",
        "        return tf.constant(retrieved_docs)\n",
        "\n",
        "# Fifth cell - Main Model\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class MultiModalTransformer(tf.keras.Model):\n",
        "    \"\"\"Colab-optimized MultiModal Transformer\"\"\"\n",
        "    def __init__(self, config: Dict[str, Any], knowledge_base: List[Dict[str, Any]]):\n",
        "        super(MultiModalTransformer, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "\n",
        "        # Core components\n",
        "        self.wte = tf.keras.layers.Embedding(config['n_vocab'], config['n_embd'])\n",
        "        self.wpe = tf.keras.layers.Embedding(config['n_ctx'], config['n_embd'])\n",
        "        self.drop = tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = [TransformerBlock(config['n_embd'], config['n_head'])\n",
        "                      for _ in range(config['n_layer'])]\n",
        "        self.ln_f = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "        # Task-specific components\n",
        "        self.retriever = FAISSRetriever(knowledge_base, config['dim'], config['num_results'])\n",
        "\n",
        "        # Simplified task heads for Colab\n",
        "        self.task_heads = {\n",
        "            'text_generation': tf.keras.layers.Dense(config['n_vocab']),\n",
        "            'classification': tf.keras.layers.Dense(config['n_vocab'], activation='softmax')\n",
        "        }\n",
        "\n",
        "    def call(self, inputs, task='text_generation', training=False):\n",
        "        if isinstance(inputs, tuple):\n",
        "            text_ids = inputs[0]\n",
        "        else:\n",
        "            text_ids = inputs\n",
        "\n",
        "        # Get embeddings\n",
        "        x = self.wte(text_ids)\n",
        "\n",
        "        # Add position embeddings\n",
        "        positions = tf.range(0, tf.shape(x)[1], dtype=tf.int32)[tf.newaxis, :]\n",
        "        x = x + self.wpe(positions)\n",
        "        x = self.drop(x, training=training)\n",
        "\n",
        "        # Apply transformer blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x, training=training)\n",
        "\n",
        "        x = self.ln_f(x)\n",
        "\n",
        "        # Task-specific output\n",
        "        return self.task_heads[task](x)\n",
        "\n",
        "# Sixth cell - Training and Testing\n",
        "# Create test data\n",
        "def create_test_data(batch_size=2, seq_length=10):\n",
        "    return tf.random.uniform((batch_size, seq_length),\n",
        "                           maxval=config['n_vocab'],\n",
        "                           dtype=tf.int32)\n",
        "\n",
        "# Initialize knowledge base\n",
        "knowledge_base = [\n",
        "    {'text': f'Example {i}', 'vector': np.random.rand(config['dim'])}\n",
        "    for i in range(100)\n",
        "]\n",
        "\n",
        "# Initialize model\n",
        "model = MultiModalTransformer(config, knowledge_base)\n",
        "\n",
        "# Test model\n",
        "test_input = create_test_data()\n",
        "start_time = time.time()\n",
        "output = model(test_input, task='text_generation')\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Model test successful!\")\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Inference time: {(end_time - start_time)*1000:.2f}ms\")\n",
        "\n",
        "# Seventh cell - Example Usage\n",
        "# Example: Text generation\n",
        "input_text = create_test_data(batch_size=1, seq_length=20)\n",
        "generated = model(input_text, task='text_generation')\n",
        "print(\"Text generation output shape:\", generated.shape)\n",
        "\n",
        "# Example: Classification\n",
        "input_text = create_test_data(batch_size=4, seq_length=15)\n",
        "classifications = model(input_text, task='classification')\n",
        "print(\"Classification output shape:\", classifications.shape)\n",
        "\n",
        "# Save model\n",
        "model.save('multimodal_transformer_colab.keras')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsCFf75ZRu1_",
        "outputId": "27ae1f3c-b8b5-40d0-8271-0773e1248609"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "GPU Available: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'multi_modal_transformer_12', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model test successful!\n",
            "Input shape: (2, 10)\n",
            "Output shape: (2, 10, 50000)\n",
            "Inference time: 2939.41ms\n",
            "Text generation output shape: (1, 20, 50000)\n",
            "Classification output shape: (4, 15, 50000)\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ]
}